#Levels of mental activities
Based on Marvin Minksy chapter of "The emotion machine"

##Everyday example

`Joan is starting to cross the street on the way to deliver her finished report. While thinking about what to say at the meeting, she hears a sound and turns her head—and sees a quickly oncoming car. Uncertain whether to cross or retreat but uneasy about arriving late, Joan decides to sprint across the road. She later remembers her injured knee and reflects upon her impulsive decision. “If my knee had failed, I could have been killed—and what would my friends have thought of me?”`

##Model of six

![Model of six](http://web.media.mit.edu/~minsky/E5/eb5_files/image001.png)

* **Inborn, Instinctive Reactions**: Joan hears a sound and turns her head. We are born with instincts that help us to survive.
* **Learned Reactions**: She sees a quickly oncoming car. Joan had to learn that certain conditions demand specific ways to react.
* **Deliberative Thinking**: What to say at the meeting. Joan considers several alternatives and tries to decide which would be best.
* **Reflective Thinking**: Joan reflects on her decision. Here she reacts not to external events but happenings inside her brain.
* **Self-Reflective Thinking**: Uneasy about arriving late. Here we find her thinking about plans that she has made for herself.
* **Self-Conscious Emotions**: What would my friends have thought of me? Here Joan asks how well her actions agreed with her ideals.

##Instinctive Reactions

![IF DO](http://web.media.mit.edu/~minsky/E5/eb5_files/image002.png)

* **IF** A THING TOUCHES YOUR SKIN, **DO** BRUSH IT AWAY.
* **IF** THAT DOESN’T WORK, **DO** MOVE YOUR BODY AWAY.
* **IF** A LIGHT IS TOO BRIGHT, **DO** TURN YOUR FACE AWAY.

![IF Situation and Goal DO](http://web.media.mit.edu/~minsky/E5/eb5_files/image003.png)

##Learned Reactions

![Learned reactions](http://web.media.mit.edu/~minsky/E5/eb5_files/image005.png)

When an animal faces a new situation, it tries a random sequence of actions. Then, if one of these is followed by some “reward,” that reaction gets “reinforced.” This makes that reaction more likely to happen when that animal faces the same situation again

In any case, although many of our actions are based on inborn, instinctive reactions to things, we’re constantly developing new ways to react to situations—this requires a second layer for our model of how our brains are organized.

##Deliberative thinking

If a car is approaching, Do retreat. If in street, Do cross the street. However, for Joan to make decisions like this, she needs some way to predict and compare the possible futures those actions might bring. What could help Joan to make such predictions? The simplest way would be for her to possess a collection of three-part **If + Do -> Then** rules, where each **If** describes a situation, each **Do** describes a possible action, and each **Then** depicts what might be a possible result of doing that action.

![If do then](http://web.media.mit.edu/~minsky/E5/eb5_files/image007.png)

* **If** in street and **Do** retreat, **Then** arrive a bit later.

* **If** in street and **Do** cross, **Then** be slightly earlier

* **If** in street and **Do** cross, **Then** may be injured.

But what if more than one such rule applies to the present situation. Then one could choose which rule to use by comparing the different results they predict:

![Alternative manipulaiton](http://web.media.mit.edu/~minsky/E5/eb5_files/image008.png)

###Four step plan to build an arch

![Four step plan to build an arch](http://web.media.mit.edu/~minsky/E5/eb5_files/image012.png)

![Both side search](http://web.media.mit.edu/~minsky/E5/eb5_files/image018.png)

But wait, there’s more. Suppose that you have some way to guess where that middle place M might be. Then you could split each ten-step tree into a pair of much smaller five-step ones. If all this works, then your total search will now be almost ten thousand times smaller than the original search!

![Guess strategy](http://web.media.mit.edu/~minsky/E5/eb5_files/image019.png)

###Logic vs. Commonsense

If A implies B, and B implies C, then A implies C. But when does such “logical thinking” work?

So using logic is somewhat like walking a plank; it assumes that each separate step is correct—whereas commonsense thinking demands more support; one must add evidence after every few steps.

![Logic vs. Commonsense](http://web.media.mit.edu/~minsky/E5/eb5_files/image020.png)

And those frailties grow exponentially with increasingly longer chains, because every additional inference-step may give the chain more ways to break. This is why, when people present their arguments, they frequently interrupt themselves to add more evidence or analogies; they sense the need to further support the present step before they proceed to the next one.

##Reflective thinking

So far as any of us can recall, we’ve always been able to do such things: we simply remember our earlier thoughts and then proceed to think about them. However, when we look more closely, we see that this requires a lot of machinery.

![Reflective thinking](http://web.media.mit.edu/~minsky/E5/eb5_files/image022.png)

Student: Would we want to say "conscious" for such a machine? It includes most of the features you mentioned in Chapter 4-5, namely, short-term memory, serial processing, and high-level descriptions.

##Self-reflection

Our self-reflective level does more than does the reflective layer discussed above: it not only considers some recent thoughts, but it also thinks about the entity that had those thoughts—as when Carol said in Section 5-3, “I simply imagined an arch in my mind—and saw where each of the blocks should go.” This shows that she is using a model of herself (like the one in Chapter 4-7) that describes some of her goals and abilities.

![Self-reflection](figure18_self_reflections.png)

To see the importance of self-reflection, consider how smart it is to know you’re confused (as opposed to being confused without knowing this)—because then you can tell yourself to elevate to a larger-scale view of your motives and goals. This could help you to recognize that you have lost track of what you were trying to do, or have been wasting time on minor details, or that you chose a poor goal to pursue. This could lead to your making a better plan—or might even lead to a large-scale cascade like, “Just thinking about this makes me feel ill. Perhaps it’s time to switch to some completely different activity.

##Self-conscious reflection

Joan must have built some models of the kinds of ideas that she "ought" to have. Then when she finds conflicts between how she behaves and the values of those to whom she’s attached, this could lead to the kinds of cascades we called "self-conscious emotions".

... those boundaries are indistinct. Even one’s simplest deliberations may involve "self-reflective thoughts" about how to allocate one’s time and resources—as in, "If this doesn’t work, then I’ll have to try that," or "I have already spent too much time on it."

![self-conscious reflections](http://web.media.mit.edu/~minsky/E5/eb5_files/image024.png)

##Imagination

![Portrait0](http://web.media.mit.edu/~minsky/E5/eb5_files/image026.png)
![Portrait1](http://web.media.mit.edu/~minsky/E5/eb5_files/image027.png)

How do you recognize features in pictures so sparse that a nose or an eye is but three or four patches of darkness or light? Clearly, you do this by using additional knowledge. For example, when you sit at a table across from your friends, you cannot see their backs or legs—but your knowledge-based systems assume by default that all those body-parts are present. Thus we take our perceptual talents for granted—but ‘seeing’ seems simple only because the rest of our minds are virtually blind to the processes that we use to do it. 

![Information flows in Builder earlier version](http://web.media.mit.edu/~minsky/E5/eb5_files/image031.png)

Information flows in Builder earlier version.

![Information flows in Builder later version](http://web.media.mit.edu/~minsky/E5/eb5_files/image032.png)

Information flows in Builder later version.

Richard Gregory 1998: "Such a major contribution of stored knowledge to perception is consistent with the recently discovered richness of downgoing pathways in brain anatomy. Some 80% of fibers to the lateral geniculate nucleus relay station come downwards from the cortex, and only about 20% from the retinas."

All this means that the higher levels of your brain never perceive a visual scene as a mere collection of pigment spots; instead, your Scene Describers would represent an arch made of blocks in larger-scale terms like (for example) "horizontal block on top of two upright ones."

![Series of guesses](http://web.media.mit.edu/~minsky/E5/eb5_files/image035.png)

##Prediction Machines

![Prediction machines loop](http://web.media.mit.edu/~minsky/E5/eb5_files/image046.png)

 There are two reasons to include that pair of "Suppressor Bands" First, while you are imagining a future condition, you do not want this to be replaced by a description of the present condition; also, you don’t yet want your muscles to perform the imagined action until you have considered some other options. So you need some way to disconnect your mind, to enable you to "stop and think" before selecting which action to take.11 (This could use the same machinery that disconnects our minds from our bodies when we are dreaming while we sleep.)

By repeating its cycle of operation, such a machine could look further into the future, by using the searching and planning schemes ...

##References

1. [Marvin Minsky, The emotion machine Draft, Levels of mental activities](http://web.media.mit.edu/~minsky/E5/eb5.html)
