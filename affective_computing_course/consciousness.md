# Consciousness

# Icebreaker

Soul?

## Marvin Minsky
Based on Marvin Minksy chapter of "The emotion machine"

### What is Consciousness?

Sri Chinmoy 2003: "Consciousness is the inner spark or inner link in us, the golden link within us that connects our highest and most illumined part with our lowest and most unillumined part."

Some philosophers even insist that no one has better ideas about this.

Jerry Fodor 1992: "Nobody has the slightest idea how anything material could be conscious. Nobody even knows what it would be like to have the slightest idea about how anything material could be conscious. So much for the philosophy of consciousness."

For, consciousness is one of those suitcase-like words that we use for many types of processes, and for different kinds of purposes. It’s the same for most of our other words about minds, such as awareness, sentience, or intelligence.

Thinker 1: Consciousness is what binds all our mental events together, and thus unifies our present, past, and future into our continuous sense of experience. 

Thinker 2: Consciousness makes us "aware" of ourselves, and gives us our sense of identity; it is what animates our minds and gives us our sense of being alive. 

Thinker 3: Consciousness is what gives things meaning to us; without it, we would not even know we had feelings.

## Unpacking the Suitcase of Consciousness

Aaron Sloman 1994: "It is not worth asking how to define consciousness, how to explain it, how it evolved, what its function is, etc., because there’s no one thing for which all the answers would be the same. Instead, we have many sub-capabilities, for which the answers are different: e.g., different kinds of perception, learning, knowledge, attention control, self-monitoring, self-control, etc."

### Everyday example

Joan is starting to cross the street on the way to deliver her finished report. While thinking about what to say at the meeting, she hears a sound and turns her head—and sees a quickly oncoming car. Uncertain as to whether to cross or retreat, but uneasy about arriving late, Joan decides to sprint across the road. She later remembers her injured knee and reflects upon her impulsive decision. "If my knee had failed, I could have been killed. Then what would my friends have thought of me?"

* **Reaction**: Joan reacted quickly to that sound.
* **Identification**: She recognized it as being a sound.
* **Specification**: She classified it as the sound of a car.
* **Attention**: She noticed certain things rather than others.
* **Indecision**: She wondered whether to cross or retreat.
* **Imagining**: She envisioned two possible future conditions.
* **Selection**: She selected a way to choose among options.
* **Decision**: She chose one of several alternative actions.
* **Planning**: She constructed a multistep action plan.
* **Reconsideration**: Later she reconsidered this choice.

**From other perspective:**

* **Learning**: She created descriptions and stored them away.
* **Recollecting**: She retrieved descriptions of prior events.
* **Embodiment**: She tried to describe her body’s condition.
* **Expression**: She constructed some verbal representations.
* **Narration**: She arranged these into storylike structures.
* **Intention**: She changed some goals and priorities.
* **Apprehension**: She was uneasy about arriving late.
* **Reasoning**: She made various kinds of inferences.

**Processes**

* **Reflection**: She thought about what she had recently done.
* **Self-Reflection**: She reflected on what she had thought about.
* **Empathy**: She imagined some other persons’ thoughts.
* **Reformulation**: She revised some of her representations.
* **Moral Reflection**: She evaluated what she has done.
* **Self-Awareness**: She characterized her mental condition.
* **Self-Imaging**: She made and used models of herself.
* **Sense of Identity**: She regarded herself as an entity.

# Icebreaker

1. Is the consciousness needed for the AI?
1. Is a consciousness achievable for the AI?

### a-Brains and B-Brains

![A-Brains and B-Brains](http://web.media.mit.edu/~minsky/E4/eb4_files/image008.gif)

**A-Brain** gets some signals from the external world (via such organs as eyes, ears, nose, and skin)—and that it also can react to these by sending signals that make your muscles move. By itself, the A-Brain is a separate animal that only reacts to external events but has no sense of what they might mean.

**B-Brain** is connected so that it can react to signals that it receives from A, and then can react by sending signals to A. However, B has no direct connection to the outer world, so, like the prisoners in Plato’s cave, who see only shadows on a wall, the B-Brain mistakes A’s descriptions for real things. The B-Brain does not realize that what it perceives are not objects in the external world but are merely events in the A-Brain itself.


![A-Brains, B-Brains, C-Brains](http://web.media.mit.edu/~minsky/E4/eb4_files/image009.gif)


### Model of six

![Model of six](http://web.media.mit.edu/~minsky/E5/eb5_files/image001.png)

* What caused Joan to turn toward that sound? [**Instinctive**] 
* How did she know that it was the sound of a car? [**Learned**]
* What resources were used to make her decision? [**Deliberative**] 
* How did she choose which resources to use? [**Reflective**] 
* Did she feel that she made a good decision? [**Self-Reflective**] 
* Did her actions live up to her principles? [**Self-Conscious**]

**The Organism Principle**: When a system evolves to become more complex, this always involves a compromise: if its parts become too separate, then the system’s abilities will be limited—but if there are too many interconnections, then each change in one part will disrupt many others.


### How do we start thinking consciously

High level activities often include following:

1. They use the models we make of ourselves.
1. They tend to be more serial and less parallel.
1. They tend to use symbolic descriptions.
1. They make use of our most recent memories.

![Trouble detector critic](http://web.media.mit.edu/~minsky/E4/eb4_files/image005.gif)

#### Self-Models

We all construct mental models that describe our various mental states, bodies of knowledge about our abilities, depictions of our acquaintances, and collections of stories about our pasts. Then, whenever we use our models of ourselves, we tend to use terms like conscious when those reflections lead to choices we make, and we use unconscious or unintentional to describe those activities that we regard as beyond our control.

#### Serial processes

The processes involved with walking, seeing, and talking take place in different parts of your brain, so they don’t need to compete for resources—whereas, for drawing a table and drawing a chair, you are likely to need to use the same higher-level resources to form and keep track of some intricate plans.

**The Parallel Paradox**: Whenever one splits a problem into parts and tries to think about them at once, one’s intellect will get dispersed and leave less cleverness for each task. The alternative is to sequentially apply one’s full mind to each of those parts—at the cost of consuming

#### Symbolic Descriptions

![Semantic network](http://web.media.mit.edu/~minsky/E4/eb4_files/image003.gif)

#### Recent Memories

We usually think of consciousness as being about what’s happening now—that is, in the present, rather than in the past. However, it would always take some amount of time for any particular part of a brain or machine to find out what other parts have recently done. For example, suppose that someone asked, "Are you aware that you’re touching your ear?" You would not be able to reply until your language resources had time to react to signals from other parts of your brain that, in turn, have reacted to prior events.

#### How Do We Recognize Consciousness?

![Trouble detector](http://web.media.mit.edu/~minsky/E4/eb4_files/image005.gif)![Conscious detector](http://web.media.mit.edu/~minsky/E4/eb4_files/image004.gif)

**The Immanence Illusion**: For most of the questions you would otherwise ask, some answers will have already arrived before the higher levels of your mind have had enough time to ask for them.

## Igor Alexander

Let **A** be an agent in a sensorily-accessible world **S**. For **A** to be conscious of **S** it is necessary that:

### Axiom 1 (Depiction)

**A** has perceptual states that depict parts of **S**.

### Axiom 2 (Imagination)

**A** has internal imaginational states that *recall* parts of **S** or fabricate **S-like** sensations.

### Axiom 3 (Attention):

**A** is capable of selecting which parts of **S** to depict or what to imagine.

### Axiom 4 (Planning):

**A** has means of control over imaginational state *sequences* to plan actions.

### Axiom 5 (Emotion):

**A** has additional **affective states** that evaluate planned actions and determine the ensuing action .

![minimal consciousness](minimal_consciousness.png)

## Neurophysiological view

![Claustrum](http://upload.wikimedia.org/wikipedia/commons/5/50/Gray_718-emphasizing-claustrum.png)

When the team zapped the area with high frequency electrical impulses, the woman lost consciousness. She stopped reading and stared blankly into space, she didn't respond to auditory or visual commands and her breathing slowed. As soon as the stimulation stopped, she immediately regained consciousness with no memory of the event. The same thing happened every time the area was stimulated during two days of experiments 

## References 

1. [Marvin Minsky, lecture consciousness, part 1](https://www.youtube.com/watch?v=qJZ_1a-t_sA&t=1s)
1. [Marvin Minsky, lecture consciousness, part 2](https://www.youtube.com/watch?v=oG6FyY2r9G0)
1. [Marvin Minsky, The emotion machine Draft, Consciousness](http://web.media.mit.edu/~minsky/E4/eb4.html)
1. [Igor Aleksander and Barry Dunmall, Axioms and Tests for the Presence of Minimal Consciousness in Agents](https://www.researchgate.net/publication/233613244_Axioms_and_Tests_for_the_Presence_of_Minimal_Consciousness_in_Agents_I_Preamble)
1. [David Chalmers, Consciousness as a Fundamental Building Block of the Universe](http://www.scienceandnonduality.com/consciousness-as-fundamental-building-in-the-universe/)
1. [NewScientist, Consciousness on-off switch discovered deep in brain](http://www.newscientist.com/article/mg22329762.700-consciousness-onoff-switch-discovered-deep-in-brain.html?page=1#.U8f0rR9d7Qo)
1. [Claustrum, Wikipedia page](http://en.wikipedia.org/wiki/Claustrum)
