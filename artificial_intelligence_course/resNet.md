# Deep Residual Learning

## Biological analogy

![ResNet building block](https://neurohive.io/wp-content/uploads/2019/01/resnet-570x328.png)

![Piramidal cell](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Piramidal_cell.svg/800px-Piramidal_cell.svg.png)

The brain has structures similar to residual nets, as cortical layer VI neurons get input from layer I, skipping intermediary layers.[6] In the figure this compares to signals from the apical dendrite (3) skipping over layers, while the basal dendrite (2) collects signals from the previous and/or same layer.[note 1][7] Similar structures exists for other layers.[8] How many layers in the cerebral cortex compare to layers in an artificial neural network is not clear, nor whether every area in the cerebral cortex exhibits the same structure, but over large areas they appear similar.

![CC](https://camo.githubusercontent.com/a80105da49b0237b63c2db8f63802be48852f724/68747470733a2f2f63312e737461746963666c69636b722e636f6d2f332f323734372f343138373238343231315f313563323331316131612e6a7067)

## Architecture 

## Benchmarks


## ReLU (rectified linear unit)

![Rectifier](https://www.codeproject.com/KB/AI/1220276/ReLU-r-700.png)


## References

1. [Wiki page](https://en.wikipedia.org/wiki/Residual_neural_network)
1. [ResNet (34, 50, 101)](https://neurohive.io/en/popular-networks/resnet/)
1. [Wide Residual Networks](https://arxiv.org/pdf/1605.07146.pdf)
1. [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)
